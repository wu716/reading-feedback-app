#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è¯­éŸ³è¯†åˆ«åŠŸèƒ½
"""
import os
import sys
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_speech_recognition():
    """æµ‹è¯•è¯­éŸ³è¯†åˆ«åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•è¯­éŸ³è¯†åˆ«åŠŸèƒ½")
    print("=" * 50)
    
    # æ£€æŸ¥ Vosk æ¨¡å‹
    from app.self_talk.speech_recognition import is_speech_recognition_available, transcribe_audio_file
    
    print("1. æ£€æŸ¥è¯­éŸ³è¯†åˆ«æœåŠ¡çŠ¶æ€...")
    is_available = is_speech_recognition_available()
    print(f"   è¯­éŸ³è¯†åˆ«æœåŠ¡: {'âœ… å¯ç”¨' if is_available else 'âŒ ä¸å¯ç”¨'}")
    
    if not is_available:
        print("âŒ è¯­éŸ³è¯†åˆ«æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ï¼š")
        print("   - Vosk åº“æ˜¯å¦å·²å®‰è£…: pip install vosk")
        print("   - æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨: models/vosk-model-small-cn-0.22")
        return False
    
    print("2. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
    model_path = "models/vosk-model-small-cn-0.22"
    if os.path.exists(model_path):
        print(f"   âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨: {model_path}")
        
        # æ£€æŸ¥æ¨¡å‹ç›®å½•å†…å®¹
        model_files = os.listdir(model_path)
        print(f"   æ¨¡å‹æ–‡ä»¶æ•°é‡: {len(model_files)}")
        for file in model_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
            print(f"   - {file}")
        if len(model_files) > 5:
            print(f"   ... è¿˜æœ‰ {len(model_files) - 5} ä¸ªæ–‡ä»¶")
    else:
        print(f"   âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    print("3. æ£€æŸ¥ä¸Šä¼ ç›®å½•...")
    upload_dir = "uploads/self_talks"
    if not os.path.exists(upload_dir):
        os.makedirs(upload_dir)
        print(f"   âœ… åˆ›å»ºä¸Šä¼ ç›®å½•: {upload_dir}")
    else:
        print(f"   âœ… ä¸Šä¼ ç›®å½•å­˜åœ¨: {upload_dir}")
    
    print("4. æµ‹è¯•éŸ³é¢‘æ–‡ä»¶å¤„ç†...")
    # åˆ›å»ºä¸€ä¸ªæµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼ˆé™éŸ³ï¼‰
    test_audio_path = os.path.join(upload_dir, "test_audio.wav")
    
    try:
        import wave
        import struct
        
        # åˆ›å»º1ç§’çš„é™éŸ³WAVæ–‡ä»¶
        sample_rate = 16000
        duration = 1  # 1ç§’
        samples = [0] * (sample_rate * duration)
        
        with wave.open(test_audio_path, 'w') as wav_file:
            wav_file.setnchannels(1)  # å•å£°é“
            wav_file.setsampwidth(2)  # 16ä½
            wav_file.setframerate(sample_rate)  # 16kHz
            
            for sample in samples:
                wav_file.writeframes(struct.pack('<h', sample))
        
        print(f"   âœ… åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ–‡ä»¶: {test_audio_path}")
        
        # æµ‹è¯•è¯­éŸ³è¯†åˆ«
        print("5. æµ‹è¯•è¯­éŸ³è¯†åˆ«...")
        transcript = transcribe_audio_file(test_audio_path)
        
        if transcript is not None:
            print(f"   âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ: '{transcript}'")
        else:
            print("   âš ï¸ è¯­éŸ³è¯†åˆ«è¿”å›ç©ºç»“æœï¼ˆé™éŸ³æ–‡ä»¶æ­£å¸¸ï¼‰")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        os.remove(test_audio_path)
        print("   âœ… æ¸…ç†æµ‹è¯•æ–‡ä»¶")
        
    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    print("\nğŸ‰ è¯­éŸ³è¯†åˆ«åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    print("=" * 50)
    return True

if __name__ == "__main__":
    # ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸‹è¿è¡Œ
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    
    success = test_speech_recognition()
    sys.exit(0 if success else 1)
